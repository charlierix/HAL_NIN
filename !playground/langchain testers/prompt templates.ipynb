{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template Types\n",
    "https://v02.api.js.langchain.com/modules/langchain_core_prompts.html\n",
    "\n",
    "https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.prompt.PromptTemplate.html\n",
    "\n",
    "https://cheatsheet.md/langchain-tutorials/langchain-prompts.en\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/modules/model_io/prompts/\n",
    "\n",
    "https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.prompt.PromptTemplate.html\n",
    "\n",
    "js.langchain.com\n",
    "\n",
    "api.python.langchain.com\n",
    "\n",
    "machinelearningspot.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    'Base PromptTemplate',\n",
    "    'Base Chat PromptTemplate',\n",
    "\n",
    "    'AI Message PromptTemplate',\n",
    "\n",
    "    'Chat PromptTemplate',\n",
    "    'Chat Message PromptTemplate',\n",
    "\n",
    "    'FewShot PromptTemplate',\n",
    "    'FewShot Chat Message PromptTemplate',\n",
    "    'FewShot PromptWithTemplates',\n",
    "\n",
    "    'Human Message PromptTemplate',\n",
    "\n",
    "    'Pipeline PromptTemplate',\n",
    "\n",
    "    'String PromptTemplate',\n",
    "\n",
    "    'System Message PromptTemplate',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "random.seed()\n",
    "\n",
    "COLOR_MIN = 96\n",
    "COLOR_MAX = 160\n",
    "\n",
    "# Returns a color, but tries to avoid gray by forcing the numbers away from center\n",
    "def get_rand_color_nongray(color_min, color_max):\n",
    "    # Generate an array with 3 random numbers in [color_min, color_max]\n",
    "    nums = [random.randint(color_min, color_max) for _ in range(3)]\n",
    "\n",
    "    center = (color_min + color_max) / 2\n",
    "    closest_num = min((abs(center - x), i, x) for i, x in enumerate(nums))  # Find the number and its index with smallest distance to midpoint\n",
    "\n",
    "    others = [num for i, num in enumerate(nums) if i != closest_num[1]]\n",
    "\n",
    "    avg_other_two = sum(others) / len(others)\n",
    "\n",
    "    # is the the correct syntax for ternary?\n",
    "    new_val = color_max if avg_other_two < center else color_min\n",
    "    nums[closest_num[1]] = new_val\n",
    "\n",
    "    return '#%02X%02X%02X' % (nums[0], nums[1], nums[2])\n",
    "\n",
    "# Iterates each line, stores distinct words as colors, returns html of ul that shows each word with that color\n",
    "def get_colored_ul(lines):\n",
    "    words_colors = defaultdict(str)\n",
    "\n",
    "    retVal = '<ul style=\"list-style-type: none;\">'\n",
    "\n",
    "    for line in lines:\n",
    "        colored_words = []\n",
    "\n",
    "        for word in line.split():\n",
    "            if word not in words_colors:\n",
    "                #color = '#%02X%02X%02X' % (random.randint(COLOR_MIN, COLOR_MAX), random.randint(COLOR_MIN, COLOR_MAX), random.randint(COLOR_MIN, COLOR_MAX))\n",
    "                color = get_rand_color_nongray(COLOR_MIN, COLOR_MAX)\n",
    "                words_colors[word] = color\n",
    "\n",
    "            colored_words.append(f'<span style=\"color:{words_colors[word]}\">{word}</span>')\n",
    "\n",
    "        line_html = ' '.join(colored_words)\n",
    "        retVal += f'<li>{line_html}</li>'\n",
    "\n",
    "    retVal += '</ul>'\n",
    "    return retVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ul style=\"list-style-type: none;\"><li><span style=\"color:#7272A0\">Base</span> <span style=\"color:#916CA0\">PromptTemplate</span></li><li><span style=\"color:#7272A0\">Base</span> <span style=\"color:#7275A0\">Chat</span> <span style=\"color:#916CA0\">PromptTemplate</span></li><li><span style=\"color:#6EA08B\">AI</span> <span style=\"color:#A06571\">Message</span> <span style=\"color:#916CA0\">PromptTemplate</span></li><li><span style=\"color:#7275A0\">Chat</span> <span style=\"color:#916CA0\">PromptTemplate</span></li><li><span style=\"color:#7275A0\">Chat</span> <span style=\"color:#A06571\">Message</span> <span style=\"color:#916CA0\">PromptTemplate</span></li><li><span style=\"color:#609E9F\">FewShot</span> <span style=\"color:#916CA0\">PromptTemplate</span></li><li><span style=\"color:#609E9F\">FewShot</span> <span style=\"color:#7275A0\">Chat</span> <span style=\"color:#A06571\">Message</span> <span style=\"color:#916CA0\">PromptTemplate</span></li><li><span style=\"color:#609E9F\">FewShot</span> <span style=\"color:#70A08B\">PromptWithTemplates</span></li><li><span style=\"color:#A06360\">Human</span> <span style=\"color:#A06571\">Message</span> <span style=\"color:#916CA0\">PromptTemplate</span></li><li><span style=\"color:#69A091\">Pipeline</span> <span style=\"color:#916CA0\">PromptTemplate</span></li><li><span style=\"color:#898760\">String</span> <span style=\"color:#916CA0\">PromptTemplate</span></li><li><span style=\"color:#60978F\">System</span> <span style=\"color:#A06571\">Message</span> <span style=\"color:#916CA0\">PromptTemplate</span></li></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "html = get_colored_ul(class_names)\n",
    "\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate\n",
    "A PromptTemplate is a template for creating string prompts. It allows you to define placeholders in the template that can be filled with specific values at runtime\n",
    "> https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.prompt.PromptTemplate.html\n",
    "\n",
    "### Message\n",
    "A Message in LangChain typically refers to a single unit of communication, such as a user input or a model’s response, within a chat or conversation context\n",
    "> https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatMessagePromptTemplate.html\n",
    "\n",
    "### Chat\n",
    "Chat refers to a conversational interface where multiple Messages are exchanged between a user and an AI model. It often involves a sequence of prompts and responses\n",
    "> https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html\n",
    "\n",
    "### Base\n",
    "Base is a foundational class or component in LangChain that other classes or components inherit from. It provides common functionality and structure\n",
    "> https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.base.BasePromptTemplate.html\n",
    "\n",
    "### AI\n",
    "AI in LangChain refers to the artificial intelligence models or agents that generate responses based on the provided prompts\n",
    "> https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.AIMessagePromptTemplate.html\n",
    "\n",
    "### FewShot\n",
    "FewShot refers to a technique where a few examples are provided within the prompt to guide the AI model’s response. This helps the model understand the desired output format and context\n",
    "> https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html\n",
    "> https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.few_shot.FewShotChatMessagePromptTemplate.html\n",
    "\n",
    "### Human\n",
    "Human typically refers to the user or the human participant in a chat or conversation with the AI model\n",
    "> https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.HumanMessagePromptTemplate.html\n",
    "\n",
    "### Pipeline\n",
    "> https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.pipeline.PipelinePromptTemplate.html\n",
    "\n",
    "### String\n",
    "String in the context of LangChain refers to text data. It is often used in prompts, responses, and other text-based inputs and outputs\n",
    "> https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.string.StringPromptTemplate.html\n",
    "\n",
    "### System\n",
    "System messages are special instructions or context provided to the AI model to guide its behavior and responses. These messages help set the tone and rules for the conversation\n",
    "> https://v02.api.js.langchain.com/classes/langchain_core_prompts.SystemMessagePromptTemplate.html\n",
    "\n",
    "### PromptWithTemplates\n",
    "PromptWithTemplates is a composite prompt that includes multiple PromptTemplate instances. It allows for more complex and structured prompt generation by combining different templates\n",
    "> https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.few_shot_with_templates.FewShotPromptWithTemplates.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Components of a PromptTemplate\n",
    "\n",
    "### String Template\n",
    "This is the core text of the prompt, potentially containing placeholders for dynamic content. You can leverage either f-strings (default) or Jinja2 syntax for formatting.\n",
    "\n",
    "<span style=\"color:red\">Don't use Jinja, it can contain code that gets run</span>\n",
    "\n",
    "### Input Variables (Optional)\n",
    "These are variables that can be passed to the template to fill in the placeholders. They provide flexibility by allowing you to customize the prompt at runtime.\n",
    "\n",
    "### Formatting Instructions (Optional)\n",
    "You can optionally specify how dynamic content should be formatted within the prompt (e.g., italics, capitalization).\n",
    "\n",
    "-----------\n",
    "\n",
    "> https://medium.com/@punya8147_26846/understanding-prompt-templates-in-langchain-f714cd7ab380"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
