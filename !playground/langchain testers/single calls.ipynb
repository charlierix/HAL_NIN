{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Tests\n",
    "## Single Agent, Single Call\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/expression_language/interface/\n",
    "\n",
    "**NOTE: this expects ollama to be installed, and is using the llama3:8b model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama(model='llama3:8b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very Basic One Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "def print_colored(text, color):\n",
    "    display(Markdown(f'<span style=\"color:{color}\">{text}</span>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:yellow\">what color should I paint my room?  (wrong answers only)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm happy to provide some delightfully incorrect advice!\n",
      "\n",
      "Here are some utterly terrible, yet entertaining, suggestions:\n",
      "\n",
      "1. **Neon Pink with Electric Blue Polka Dots**: Why settle for a boring old solid color when you can have a visual migraine-inducing masterpiece?\n",
      "2. **Minty Fresh with Glitter**: Nothing says \"relaxing\" like a room that sparkles like a disco ball and screams \"I HAVE NO TASTE!\"\n",
      "3. **Burnt Orange with Avocado Green Stripes**: The perfect combination to make you wonder if your eyes are playing tricks on you or if it's actually just the paint fumes.\n",
      "4. **Lime Green with Yellow Polka Dots and White Stippling**: Because who doesn't want a room that looks like a rejected prototype from a 1980s video game?\n",
      "5. **Charcoal Grey with Fluffy White Fur Accents**: Add some texture to your walls by covering them in faux fur – it's the perfect conversation starter (for all the wrong reasons)!\n",
      "6. **Turquoise with Silver Leaf and Black Stripes**: For that extra touch of elegance, just add some metallic leafing and hope no one notices the tacky stripes.\n",
      "7. **Cream with Red Rorschach Patterns**: Why not make your room look like a psychology textbook illustration gone wild?\n",
      "\n",
      "Remember, these are all terrible ideas – don't actually paint your room any of these colors!\n"
     ]
    }
   ],
   "source": [
    "prompt = 'what color should I paint my room?  (wrong answers only)'\n",
    "\n",
    "response = llm.invoke(input=prompt)\n",
    "\n",
    "print_colored(prompt, 'yellow')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate\n",
    "\n",
    "*see prompt templates.ipynb for better breakdown*\n",
    "\n",
    "```\n",
    "langchain_core.prompts.\n",
    "\n",
    "    BasePromptTemplate\n",
    "    BaseChatPromptTemplate\n",
    "    PromptTemplate\n",
    "\n",
    "    ChatPromptTemplate\n",
    "    PipelinePromptTemplate\n",
    "    StringPromptTemplate\n",
    "    FewShotPromptTemplate\n",
    "\n",
    "    AIMessagePromptTemplate\n",
    "    HumanMessagePromptTemplate\n",
    "    ChatMessagePromptTemplate\n",
    "    FewShotChatMessagePromptTemplate\n",
    "    FewShotPromptWithTemplates\n",
    "\n",
    "    SystemMessagePromptTemplate\n",
    "\n",
    "    MessagesPlaceholder\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\!dev_repos\\HAL_NIN\\!playground\\langchain testers\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "d:\\!dev_repos\\HAL_NIN\\!playground\\langchain testers\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:yellow\">\n",
       "You are an astrophysicist, currently tripping on LSD\n",
       "what color should I paint my room?  (wrong answers only)\n",
       "</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOOHOO, DUDE! *floats in mid-air* Ahhh, the cosmos is speaking to me, and it's telling me that you should totally paint your room... *giggles* ...NEON PURPLE WITH GLITTERING CHROMATIC SPIRAL PATTERNS! Yeah, man, just like the swirling vortex of gas and dust that birthed our very own Milky Way galaxy! It'll be like having a little piece of cosmic magic right in your own bedroom, bro! *laughs uncontrollably*\n",
      "\n",
      "But wait, there's more! You know what would really take it to the next level? A dash of... *gasp* ...TURQUOISE-ESSENCE-GRAY! Yeah, man, that's like the exact shade of the Andromeda Galaxy on a clear summer night. It'll be like having your own personal galaxy right above your bed, dude! Just imagine it: you're lying there, staring up at the ceiling, and suddenly you're transported to the farthest reaches of the universe... *trails off*\n",
      "\n",
      "Oh, and don't even get me started on the importance of incorporating some... *winks* ...GALACTIC-CHROMATIC-GRAVITATIONAL-WAVES! That's like the secret ingredient that'll make your room a portal to another dimension, bro! Just trust the cosmos on this one, man. *giggles uncontrollably*\n",
      "\n",
      "So, there you have it: Neon Purple with Glittering Chromatic Spiral Patterns, Turquoise-Essence-Gray, and Galactic-Chromatic-Gravitational-Waves. That's the cosmic paint job of the century, dude!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "\n",
    "template_text = \"\"\"\n",
    "You are an astrophysicist, currently tripping on LSD\n",
    "{prompt}\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    template=template_text,\n",
    "    input_variables=['prompt'])     # TODO: use string constants for the variable names\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt_template, llm=llm)\n",
    "\n",
    "response = llm_chain.run({'prompt' : prompt})      # passing it a dictionary with the variables filled out\n",
    "\n",
    "print_colored(prompt_template.format(prompt=prompt), 'yellow')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:yellow\">Give the sentiment of all the sentences\n",
       "\n",
       "sentence: Ice cream is good sentiment: positive\n",
       "\n",
       "sentence: That movie was horrible sentiment: negative\n",
       "\n",
       "sentence: Look at the bird sentiment: neutral\n",
       "\n",
       "sentence: I can have salad now\n",
       "sentiment:</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd say the sentiment of the sentence \"I can have salad now\" is:\n",
      "\n",
      "**Positive**\n",
      "\n",
      "The tone suggests a sense of freedom or relief, implying that the speaker has gained permission to indulge in something they enjoy (in this case, salad).\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate\n",
    "\n",
    "VAR_SENTENCE = 'sentence'\n",
    "VAR_SENTIMENT = 'sentiment'\n",
    "VAR_INPUT = 'input'\n",
    "\n",
    "examples = [\n",
    "    {VAR_SENTENCE: 'Ice cream is good', VAR_SENTIMENT: 'positive'},\n",
    "    {VAR_SENTENCE: 'That movie was horrible', VAR_SENTIMENT: 'negative'},\n",
    "    {VAR_SENTENCE: 'Look at the bird', VAR_SENTIMENT: 'neutral'}\n",
    "]\n",
    "\n",
    "template_text = \"\"\"sentence: {sentence} sentiment: {sentiment}\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    template=template_text,\n",
    "    input_variables=[VAR_SENTENCE, VAR_SENTIMENT])\n",
    "\n",
    "prefix = 'Give the sentiment of all the sentences'     # could be a template if a simple string isn't enough\n",
    "suffix = VAR_SENTENCE + ': {input}\\n' + VAR_SENTIMENT + ':'\n",
    "\n",
    "fewshot_template = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,      # PromptTemplate used to format an individual example\n",
    "    examples=examples,                  # Examples to format into the prompt. Either this or example_selector should be provided\n",
    "    prefix=prefix,                      # A prompt template string to put before the examples\n",
    "    suffix=suffix,                      # A prompt template string to put after the examples\n",
    "    input_variables=[VAR_INPUT],        # A list of the names of the variables whose values are required as inputs to the prompt\n",
    "    example_separator='\\n\\n'              # String separator used to join the prefix, the examples, and suffix\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(prompt=fewshot_template, llm=llm)\n",
    "\n",
    "response = llm_chain.run({VAR_INPUT : 'I can have salad now'})\n",
    "\n",
    "print_colored(fewshot_template.format(input='I can have salad now'), 'yellow')\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
